<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: General Tips | $whois andyregan]]></title>
  <link href="http://andyregan.net/blog/categories/general-tips/atom.xml" rel="self"/>
  <link href="http://andyregan.net/"/>
  <updated>2013-01-09T18:08:30+00:00</updated>
  <id>http://andyregan.net/</id>
  <author>
    <name><![CDATA[Andrew Regan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Specifying GPU Compute Mode At Job Submission with Torque]]></title>
    <link href="http://andyregan.net/specifying-gpu-compute-mode-at-job-submission-with-torque/"/>
    <updated>2011-07-10T00:00:00+01:00</updated>
    <id>http://andyregan.net/specifying-gpu-compute-mode-at-job-submission-with-torque</id>
    <content type="html"><![CDATA[<p>In Torque 2.5.6, 3.0.2 and later, you can specify GPU compute mode and reset GPU ECC error counts at job submission
(provided that you have configured Torque with the <strong>enable-nvidia-gpus</strong> option).</p>

<p>For CUDA 4.0 (Nvidia 270.x drivers), there are four compute modes that can be set on the GPU.</p>

<ol>
<li><strong>Default</strong> : Multiple threads can run on this GPU</li>
<li><strong>Exclusive Thread</strong> : Only one thread in one process can run on this GPU</li>
<li><strong>Prohibited</strong> : No threads are allowed to run on this GPU</li>
<li><strong>Exclusive Process</strong> : Many threads in one process will be able to run on this GPU</li>
</ol>


<p>With Torque, you can now request <strong>Default</strong>, <strong>Exclusive Thread</strong> or <strong>Exclusive Process</strong> compute modes at job
submission time. The mode you specify applies to all the GPUs you request. If you do not specify a compute mode,
then Torque will set the GPUs to <strong>Exclusive Thread</strong>.</p>

<p>For example, to request 1 GPU and with compute mode set to <strong>Exclusive Process</strong> you could define the following resource:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>qsub -l <span class="nv">nodes</span><span class="o">=</span>1:gpus<span class="o">=</span>1:exclusive_process
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>To request 1 GPU with compute mode set to <strong>Exclusive Thread</strong> and reset the ECC error counts on the GPU, you could define the following:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>qsub -l <span class="nv">nodes</span><span class="o">=</span>1:gpus<span class="o">=</span>1:reseterr:exclusive_thread
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The below table shows the various modes and their associated Torque keywords.</p>

<table>
<thead>
<tr>
<th></th>
<th> Compute Mode      </th>
<th> Keyword           </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Default           </td>
<td> shared            </td>
</tr>
<tr>
<td></td>
<td> Exclusive Thread  </td>
<td> exclusive_thread  </td>
</tr>
<tr>
<td></td>
<td> Exclusive Process </td>
<td> exclusive_process </td>
</tr>
</tbody>
</table>


<p>More information is available in <a href="http://www.adaptivecomputing.com/resources/docs/torque/3.7schedulinggpus.php">Section 3.7 of the Torque Documentation</a>.</p>

<p>Al Taufer from Adaptive Computing helpfully explained the reasoning behind the <em>shared</em> keyword in <a href="http://www.supercluster.org/pipermail/torqueusers/2011-June/013079.html">reply to a question I submitted to the Torque Users mailing list</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Libvirt + KVM : Booting From An ISO Image]]></title>
    <link href="http://andyregan.net/libvirt-kvm-booting-from-an-iso-image/"/>
    <updated>2011-06-16T00:00:00+01:00</updated>
    <id>http://andyregan.net/libvirt-kvm-booting-from-an-iso-image</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://libvirt.org/libvirtLogo.png" width="200" title="libvirt logo" ></p>

<p>If you want to boot your domain from a CDROM (for example, if you wish to re-install the OS on the VM),
you can edit its configuration so that it boots from an ISO image on the host.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>host:~# virsh edit name_of_domain
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Within the <strong>os</strong> section, add a <strong>cdrom</strong> device. Make sure that it is placed before other boot devices, such as disks.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>&lt;os&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;...
</span><span class='line'>&amp;lt;boot <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;cdrom&#39;</span>/&amp;gt;
</span><span class='line'>&amp;lt;boot <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;hd&#39;</span>/&amp;gt;
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;/os&gt;
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Add an entry for a cdrom device (or edit an existing cdrom device) such that the <strong>type</strong> is <em>file</em> and the <strong>source</strong>
is the path to the ISO image on the host.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>&lt;disk <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span> <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;cdrom&#39;</span>&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;  &amp;lt;source <span class="nv">file</span><span class="o">=</span><span class="s1">&#39;/path/to/install_media.iso&#39;</span>/&amp;gt;
</span><span class='line'>   ...
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;/disk&gt;
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Save your changes and then reboot the domain. It should have booted into the ISO image. You can then attach a console
and continue the installation.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>host:~# virt-viewer name_of_domain
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Edit</h2>

<p>I forgot (of course!) that you must undo the above changes after installation. Otherwise, it will continue to boot
into the ISO and not your shiny new OS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fixing Git Group Write Errors]]></title>
    <link href="http://andyregan.net/fixing-git-group-write-errors/"/>
    <updated>2011-06-15T00:00:00+01:00</updated>
    <id>http://andyregan.net/fixing-git-group-write-errors</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/posts/fixing-git-group-write-errors/200px-Git-logo.svg_.png" width="200" title="&#34;200px Git logo&#34;" alt="&#34;200px Git logo&#34;"></p>

<h2>The Problem</h2>

<p>When many users are committing to the same git repository, the correct group permissions must be
set. For example, when a user recently tried to commit to a shared git repository, it failed
with the following error:</p>

<p><blockquote><p>fatal: failed to write object</p></blockquote></p>

<p>Looking at the repository's config file on the server, the <strong>sharedRepository</strong> variable was not set.</p>

<h2>The Fix</h2>

<p>First, I fixed the group permissions for the repository (all the users belonged to the same group).</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>chmod -R g+swX /path/to/repository/
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Then, I set the <strong>sharedRepository</strong> variable to <em>true</em>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="nb">cd</span> /path/to/repository/
</span><span class='line'><span class="nv">$ </span>git repo-config core.sharedRepository <span class="nb">true</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>More Info</h2>

<p>More information on this variable can be found in the git-config man page.</p>

<p><blockquote><p>core.sharedRepository<br/><br/>When group (or true), the repository is made shareable between several users in a group (making sure all the files and objects are group-writable). When all (or world or everybody), the<br/><br/>repository will be readable by all users, additionally to being group-shareable. When umask (or false), git will use permissions reported by umask(2). When 0xxx, where 0xxx is an octal<br/><br/>number, files in the repository will have this mode value. 0xxx will override user´s umask value, and thus, users with a safe umask (0077) can use this option. Examples: 0660 is equivalent<br/><br/>to group. 0640 is a repository that is group-readable but not group-writable. See git-init(1). False by default.</p></blockquote></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Extract a Tar Archive to Multiple Directories Matching A Pattern]]></title>
    <link href="http://andyregan.net/extract-a-tar-archive-to-multiple-directories-matching-a-pattern/"/>
    <updated>2011-06-01T00:00:00+01:00</updated>
    <id>http://andyregan.net/extract-a-tar-archive-to-multiple-directories-matching-a-pattern</id>
    <content type="html"><![CDATA[<p>Sometimes you may need to extract the same tar archive into many directories at once.</p>

<p>The below command extracts <strong>/path/to/archive.tgz</strong> into the directories from
<strong>/path/to/destination/00</strong> to <strong>/path/to/destination/29</strong> .</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>me@host ~<span class="o">]</span><span class="nv">$ </span>ls -d /path/to/destination/<span class="o">[</span>0-2<span class="o">][</span>0-9<span class="o">]</span>/ | xargs -I <span class="o">{}</span> tar -xvzf /path/to/archive.tgz -C <span class="o">{}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Requesting GPUs At Job Submission With Torque]]></title>
    <link href="http://andyregan.net/requesting-gpus-at-job-submission-with-torque/"/>
    <updated>2011-05-09T00:00:00+01:00</updated>
    <id>http://andyregan.net/requesting-gpus-at-job-submission-with-torque</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://andyregan.net/blog/wp-content/uploads/2011/05/gpu_torque.jpg" title="A picture of a GPU card" alt="A picture of a GPU card"></p>

<p>According to the <a href="http://www.adaptivecomputing.com/resources/docs/torque/3.7schedulinggpus.php">Torque Documentation</a>, <strong>"in TORQUE 2.5.4 and later, users can request GPUs on a node at job submission"</strong>. This
post describes how to configure Torque for this functionality, allowing GPU resources to be scheduled among multiple users.</p>

<p>In a future post, I will also describe one approach that could be used to manage mutually exclusive CUDA access to NVIDIA GPUs on a
multi-GPU compute node.</p>

<p>The examples that follow involve a single workstation with 2 NVIDIA GPU devices.</p>

<h2>Informing Torque Where the GPUs Are</h2>

<p>In order for Torque to know which nodes have GPUs, you must update the <a href="http://www.adaptivecomputing.com/resources/docs/torque/1.5nodeconfig.php">nodes</a> file. In the following example, I have specified
that <strong>node1</strong> has 12 CPU cores and 2 GPU devices.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>root@service-node:~# cat /var/spool/torque/server_priv/nodes
</span><span class='line'>node1 <span class="nv">np</span><span class="o">=</span>12 <span class="nv">gpus</span><span class="o">=</span>2
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>After saving the changes, you must restart <strong>pbs_server</strong> for the change to take affect.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>root@service-node:~# /etc/init.d/pbs_server restart
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Looking at the <strong>pbsnodes</strong> output, we can see that Torque is now aware that there should be 2 GPU devices on <strong>node1</strong>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>user@login-node:~# pbsnodes -a
</span><span class='line'>node1&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt; <span class="nv">np</span> <span class="o">=</span> 12
</span><span class='line'> <span class="nv">gpus</span> <span class="o">=</span> 2
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Requesting GPUs at job submission</h2>

<p>When submitting a job, a user can request GPU devices similar to how they request CPU cores. In the following example,
I'm requesting an <a href="http://www.clusterresources.com/torquedocs21/users/2.2files.shtml#interactive">interactive job</a> with 1 node , 1 processor per node and 2 GPUs per node.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>user@login-node:~<span class="nv">$ </span>qsub -I -l <span class="nv">nodes</span><span class="o">=</span>1:ppn<span class="o">=</span>1:gpus<span class="o">=</span>2&lt;br/&gt;
</span><span class='line'>qsub: waiting <span class="k">for </span>job &lt;job id&gt; to start&lt;br/&gt;
</span><span class='line'>qsub: job &lt;job id&gt; ready
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>When the job starts, Torque populates a file whose path is specified by the environment variable <code>$PBS_GPUFILE</code>. Each
allocated GPU appears on a separate line within this file.</p>

<p>As you can see, the contents of <code>$PBS_GPUFILE</code> show that the job has been allocated GPU index 0 and 1 (the first and
second GPU) on node1 to execute on.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>user@login-node:~<span class="nv">$ </span>env | grep PBS_GPUFILE
</span><span class='line'><span class="nv">PBS_GPUFILE</span><span class="o">=</span>/var/spool/torque/aux/JOB_IDgpu
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>user@login-node:~<span class="nv">$ </span>cat /var/spool/torque/aux/JOB_IDgpu
</span><span class='line'>node1-gpu0
</span><span class='line'>node1-gpu1
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Restricting the GPUs available to CUDA to Those Allocated</h2>

<p>As specified in Torque's documentation, <strong>"it is left up to the job's owner to make sure that the job executes properly on the GPU"</strong>.</p>

<p>In my next post, I will describe how you can take advantage of the $CUDA_VISIBLE_DEVICES environment variable (available since CUDA 3.1) to restrict the GPUs available to CUDA to those allocated by Torque.</p>
]]></content>
  </entry>
  
</feed>
